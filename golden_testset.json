{"user_input":"wht is the diffrence btween Asking and Doing in user intent?","reference_contexts":["technology that can be used in many different ways. In order to learn more about how people seek to\nuse generative AI at work and outside of work, we introduce a classifier that is designed to measure the\ntype of output the user hopes to receive. Specifically, we classify messages according to user intent,\ncoding up conversations according to a simpleAsking, Doing, or Expressingrubric. The critical part\nof our classification prompt is as follows:\nIntent Prompt\nAskingAsking is seeking information or advice that will help the user be better\ninformed or make better decisions, either at work, at school, or in their\npersonal life. (e.g. \u201cWho was president after Lincoln?\u201d, \u201cHow do I create a\nbudget for this quarter?\u201d, \u201cWhat was the inflation rate last year?\u201d,\n\u201cWhat\u2019s the difference between correlation and causation?\u201d, \u201cWhat should I\nlook for when choosing a health plan during open enrollment?\u201d).\nDoingDoing messages request that ChatGPT perform tasks for the user. User is\ndrafting an email, writing code, etc. Classify messages as \u201cdoing\u201d if they\ninclude requests for output that is created primarily by the model. (e.g.\n\u201cRewrite this email to make it more formal\u201d, \u201cDraft a report summarizing\nthe use cases of ChatGPT\u201d, \u201cProduce a project timeline with milestones\nand risks in a table\u201d, \u201cExtract companies, people, and dates from this text\ninto CSV.\u201d, \u201cWrite a Dockerfile and a minimal docker-compose.yml for\nthis app.\u201d)\nExpressingExpressing statements are neither asking for information, nor for the\nchatbot to perform a task.\nConceptually,Doingconversations are delivering output that can be plugged into a production\nprocess, whileAskingconversations support decision-making but do not produce output directly, and\nExpressingconversations have little or no economic content.\nFigure 10 shows the share of messages by each intent type in our sample. 49% of user messages\nareAsking, 40% areDoing, and 11% areExpressing. The figure also shows the relationship with\nour Topic classification: the two taxonomies are correlated but not redundant:Askingqueries are\nmore likely to bePractical GuidanceandSeeking Information.Doingqueries are disproportionately\nWritingandMultimedia.Expressingqueries are disproportionatelySelf-Expression. However, the\noverlap is imperfect. For example, within thePractical Guidancetopic, anAskingmessage might\nbe advice about how to recover from a sports injury given a user\u2019s personal history, while aDoing\nmessage might request ChatGPT to produce a customized recovery and training plan that could be\nprinted or saved. WithinTechnical Help, anAskingmessage might request help understanding how\nto debug some code, while aDoingmessage might ask ChatGPT to write code for the user directly.\nFigure 11 presents shares ofAsking\/Doing\/Expressingjust for work-related messages.Doing\nconstitutes nearly 56% of work-related queries, compared to 35% forAskingand 9% forExpressing.\nNearly 35% of all work-related queries areDoingmessages related toWriting.DoingandAsking\ncomprise equal shares ofTechnical Helpqueries.\n17"],"reference":"Asking messages seek information or advice to help the user be better informed or make better decisions, without producing output directly. Doing messages request that ChatGPT perform tasks and create output, such as drafting emails or writing code. Conceptually, Doing conversations deliver output that can be used in production, while Asking conversations support decision-making.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"What work related stuff in panel A?","reference_contexts":["Panel A.Work Related\nPanel B1.Asking.\n Panel B2.Doing.\nFigure 23:(continued on next page)\n33"],"reference":"Panel A is labeled Work Related.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"how telemetry data help detect user behavior for privacy?","reference_contexts":["telemetry  data,  such  as  typing  speed,  pause  duration,  and  features  of  the  AI's  suggestion.\n6\n \nWhile\n \nthe\n \naccuracy\n \nof\n \nthese\n \npredictive\n \nmodels\n \nrequires\n \nfurther\n \nimprovement,\n \nthey\n \nopen\n \nthe\n \npossibility\n \nof\n \ncreating\n \nadaptive\n \ninterfaces\n \nthat\n \ncan\n \nprovide\n \ncontext-sensitive\n \ninterventions.\n \nFor\n \nexample,\n \nif\n \nthe\n \nsystem\n \ndetects\n \nthat\n \na\n \nuser\n \nis\n \nspending\n \nan\n \nunusually\n \nlong\n \ntime\n \nin\n \nthe\n \n\"Verifying\n \nSuggestion\"\n \nstate,\n \nit\n \ncould\n \nproactively\n \noffer\n \ndebugging\n \ntools\n \nor\n \nlinks\n \nto\n \nrelevant\n \ndocumentation.\n \nSuch\n \nadvancements\n \nwould\n \nreframe\n \nthe\n \ngoal\n \nof\n \nHAI\n \ndesign\n \naway\n \nfrom\n \nsimply\n \ngenerating\n \nbetter\n \ninitial\n \nsuggestions\n \nand\n \ntoward\n \noptimizing\n \nthe\n \nefficiency\n \nand\n \nreducing\n \nthe\n \ncognitive\n \nfriction\n \nof\n \nthe\n \nentire\n \ninteractive\n \nworkflow.\n \nIntent  Category  Description  Example  Prompt  Key  Challenges  &  Relevant  Snippets  \nInformation  Seeking  \nUsing  the  LLM  as  an  answer  engine  to  find  factual  information  or  explanations.  \n\"Explain  the  theory  of  relativity  in  simple  terms.\"  \nHallucinations,  lack  of  citations,  user  overreliance  on  plausibility.  \nContent  Generation  \nCreating  new,  original  text  for  a  specific  purpose  (e.g.,  creative  writing,  marketing  copy,  email  drafts).  \n\"Write  a  short  poem  about  autumn.\"  \nMaintaining  coherence,  avoiding  repetition,  capturing  specific  tone\/style,  potential  for  bias.  \nBrainstorming  &  Ideation  \nUsing  the  LLM  as  a  creative  partner  to  generate  a  wide  range  of  ideas  or  explore  different  angles  on  a  topic.  \n\"Give  me  10  blog  post  ideas  about  sustainable  travel.\"  \nDiversity  of  ideas,  avoiding  generic  suggestions,  building  on  user  input  effectively.  \nEditing  &  Refinement  \nImproving  existing  text  by  correcting  grammar,  rephrasing  for  clarity,  changing  tone,  or  shortening\/lengthening.  \n\"Make  this  sentence  sound  more  professional:  'I  think  we  should  do  this.'\"  \nPreserving  original  meaning,  understanding  subtle  nuances,  avoiding  over-correction."],"reference":"Telemetry data, such as typing speed, pause duration, and features of the AI's suggestion, can be used to detect user behavior. For example, if the system detects that a user is spending an unusually long time in the \"Verifying Suggestion\" state, it could proactively offer debugging tools or links to relevant documentation. These predictive models, while needing further improvement in accuracy, open the possibility of creating adaptive interfaces that provide context-sensitive interventions, aiming to optimize efficiency and reduce cognitive friction in the interactive workflow.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"Could you provide a detailed explanation of the datasets used in the analysis of ChatGPT usage and the privacy safeguards implemented to protect user data?","reference_contexts":["Lambert et al. (2024)). This second stage also typically includes a number of \u201csafety\u201d constraints to\navoid certain classes of response, especially those which are deemed harmful or dangerous (OpenAI,\n2025a).\nThis two-stage process has a common statistical interpretation: the first stage teaches the model a\nlatent representation of the world; the second stage fits a function using that representation (Bengio\net al., 2014). Pre-training the model to predict the next word effectively teaches the model a low-\ndimensional representation of text, representing only the key semantic features, and therefore rendering\nthe prompt-response problem tractable with a reasonable set of training examples.\nTwo common ways of evaluating chatbots are with benchmarks (batteries of questions with known\nanswers, e.g. Measuring Massive Multitask Language Understanding (Hendrycks et al., 2021)) and\ncomparisons of human preferences over two alternative responses to the same message (e.g. Chatbot\nArena (Chiang et al., 2024)).\n3 Data and Privacy\nIn this section, we describe the data used in the paper and the privacy safeguards we implemented. No\nmember of the research team ever saw the content of user messages, and all analyses were conducted\nin accordance with OpenAI\u2019s Privacy Policy (OpenAI, 2025c).\nThe analysis in this paper is based on the following datasets:\n1.Growth:total daily message volumes from consumer ChatGPT users between November 2022\nand September 2025, along with basic self-reported demographic information. This dataset is\nprimarily used in Section 4.\n2.Classified messages:messages classified into coarse categories.\n\u2022Sampled from all ChatGPT users:a random sample of approximately one million de-\nidentified messages from logged-in consumer ChatGPT users between May 2024 and June\n2025.14 This dataset is primarily used in Section 5.\n\u2022Sampled from a subset of ChatGPT users:two random samples of messages sent\nbetween May 2024 and July 2025 by a subset of consumer ChatGPT users (one sample at\nthe conversation level, one sample at the user level). 15 These datasets are primarily used\nin Section 6.\n3.Employment:aggregated employment and education categories based on publicly available\ndata for a subset of consumer ChatGPT users. This data is only used in Section 6.\nWe describe the contents of each dataset, the sampling procedures that produced them, and the\nprivacy protections we implemented in constructing and employing them in analysis.\n3.1 Growth Dataset\nWe compiled a dataset covering all usage on consumer ChatGPT Plans (Free, Plus, Pro) since Chat-\nGPT\u2019s launch in November 2022. We exclude users on non-consumer plans (Business f.k.a. Teams,\n14The exact beginning and end dates of this sample are May 15, 2024 and June 26, 2025.\n15The exact beginning and end dates of this sample are May 15, 2024 and July 31, 2025.\n5"],"reference":"The analysis is based on several datasets: 1) Growth dataset, which includes total daily message volumes from consumer ChatGPT users between November 2022 and September 2025, along with basic self-reported demographic information, primarily used in Section 4; 2) Classified messages dataset, consisting of messages classified into coarse categories, sampled from all ChatGPT users as a random sample of approximately one million de-identified messages between May 2024 and June 2025, primarily used in Section 5, and sampled from a subset of ChatGPT users with two random samples of messages sent between May 2024 and July 2025 at the conversation and user levels, primarily used in Section 6; 3) Employment dataset, which includes aggregated employment and education categories based on publicly available data for a subset of consumer ChatGPT users, used only in Section 6. Privacy safeguards include that no member of the research team ever saw the content of user messages, and all analyses were conducted in accordance with OpenAI's Privacy Policy.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"What user metadata is included in the ChatGPT message dataset to help understand usage while preserving privacy?","reference_contexts":["Enterprise, Education).\nFor each user and day, this dataset reports the total number of messages sent by the user on that\nday. It also reports, for each message, de-identified user metadata, including the timestamp of their\nfirst interaction with ChatGPT, the country from which their account is registered, their subscription\nplan on each day, and their self-reported age (reported in coarse 5\u20137-year buckets to protect user\nprivacy).\n3.2 Classified Messages\nTo understand usage while preserving user privacy, we construct message-level datasets without any\nhuman ever reading the contents of a message. See Figure 1 for an overview of the privacy-preserving\nclassification pipeline. Messages are categorized according to 5 different LLM-based classifiers. The\nclassifiers are introduced in more detail in Section 5, their exact text is reproduced in Appendix A,\nand our validation procedure is described in Appendix B.\nSampled From All ChatGPT Users.We uniformly sampled approximately 1.1 million conver-\nsations, and then sampled one message within each conversation, with the following restrictions:\n1. We only include messages from May 2024 to July 2025.\n2. We exclude conversations from users who opted out of sharing their messages for model training.\n3. We exclude users who self-report their age as under 18.\n4. We exclude conversations that users have deleted and from users whose accounts have been\ndeactivated or banned.\n5. We exclude logged-out users, 16 which represented a minority share of ChatGPT users over the\nsample period.\nOur sample is drawn from a table that is itself sampled, where the sampling rate varied over time.\nWe thus adjust our sampling weights to maintain a fixed ratio with aggregate messages sent.\nSampled From a Subset of ChatGPT Users.We construct two samples of classified messages\nfrom a subset of ChatGPT users (approximately 130,000 users). This sample of users does not include\nany users who opted out of sharing their messages for training, nor does it include users whose self-\nreported age is below 18, nor does it include users who have been banned or deleted their accounts.\nThe first sample contains classifications of 1.58 million messages from this subset of users, sampled\nat the conversation level (a conversation is a series of messages between the user and chatbot). This\nsample is constructed such that the user\u2019s representation in the data is proportional to overall message\nvolume. The second sample contains messages sent from this subset of users, sampled at the user level\nwith up to six messages from each user in the group.\n16ChatGPT became available to logged-out users in April 2024, i.e., users could use ChatGPT without signing up\nfor an account with an email address. However, messages from logged-out users are only available in our dataset from\nMarch 2025, thus for consistency we drop all messages from logged-out users.\n6"],"reference":"The ChatGPT message dataset includes de-identified user metadata such as the timestamp of their first interaction with ChatGPT, the country from which their account is registered, their subscription plan on each day, and their self-reported age reported in coarse 5\u20137-year buckets to protect user privacy.","synthesizer_name":"single_hop_specific_query_synthesizer"}
