{"user_input":"How has the share of non-work-related ChatGPT messages changed between June 2024 and June 2025?","reference_contexts":["Month Non-Work (M)(%)Work (M)(%)Total Messages (M)\nJun 2024 238 53% 213 47% 451\nJun 2025 1,911 73% 716 27% 2,627\nTable 1:ChatGPT daily message counts (millions), broken down by likely work-related or non-work-related.\nTotal daily counts are exact measurements of message volume from all consumer plans. Daily counts of work\nand non-work related messages are estimated by classifying a random sample of conversations from that day.\nSampling is done to exclude users who opt-out of sharing their messages for model training, users who self-\nreport their age as under 18, logged-out users, deleted conversations, and accounts which have been deactivated\nor banned (details available in Section 3). Reported values are 7-day averages (to smooth weekly fluctuation)\nending on the 26th of June 2024 and 26th of June 2025.\nmessages have grown continuously, but non-work messages have grown faster and now represent more\nthan 70% of all consumer ChatGPT messages. While most economic analysis of AI has focused on its\nimpact on productivity in paid work, the impact on activity outside of work (home production) is on a\nsimilar scale and possibly larger. The decrease in the share of work-related messages is primarily due to\nchanging usage within each cohort of users rather than a change in the composition of new ChatGPT\nusers. This finding is consistent with Collis and Brynjolfsson (2025), who use choice experiments to\nuncover willingness-to-pay for generative AI and estimate a consumer surplus of at least$97 billion\nin 2024 alone in the US.\nWe next report on a classification of messages using a taxonomy developed at OpenAI for un-\nderstanding product usage (\u201cconversation classifier\u201d). Nearly 80% of all ChatGPT usage falls into\nthree broad categories, which we callPractical Guidance,Seeking Information, andWriting.Practical\nGuidanceis the most common use case and includes activities like tutoring and teaching, how-to\nadvice about a variety of topics, and creative ideation. 7 Seeking Informationincludes searching for\ninformation about people, current events, products, and recipes, and appears to be a very close sub-\nstitute for web search.Writingincludes the automated production of emails, documents and other\ncommunications, but also editing, critiquing, summarizing, and translating text provided by the user.\nWritingis the most common use case at work, accounting for 40% of work-related messages on average\nin June 2025. About two-thirds of allWritingmessages ask ChatGPT to modify user text (editing,\ncritiquing, translating, etc.) rather than creating new text from scratch. About 10% of all messages\nare requests for tutoring or teaching, suggesting that education is a key use case for ChatGPT.\nTwo of our findings stand in contrast to other work. First, we find the share of messages related\nto computer coding is relatively small: only 4.2% of ChatGPT messages are related to computer\nprogramming, compared to 33% of work-related Claude conversations Handa et al. (2025).8 Second, we\nfind the share of messages related to companionship or social-emotional issues is fairly small: only 1.9%\nof ChatGPT messages are on the topic ofRelationships and Personal Reflectionand 0.4% are related\n7The difference betweenPractical GuidanceandSeeking Informationis that the former is highly customized to the\nuser and can be adapted based on conversation and follow-up, whereas the latter is factual information that should be\nthe same for all users. For example, users interested in running might ask ChatGPT for the Boston Marathon qualifying\ntimes by age and gender (Seeking Information), or they might ask for a customized workout plan that matches their\ngoals and current level of fitness (Practical Guidance).\n8Handa et al. (2025) report that 37% of conversations are mapped to a \u201ccomputer and mathematical\u201d occupation\ncategory, and their Figure 12 shows 30% or more of all imputed tasks are programming or IT-related. We believe the\ndiscrepancy is partly due to the difference in types of users between Claude and ChatGPT, additionally Handa et al.\n(2025) only includes queries that \u201dpossibly involve an occupational task\u201d.\n2"],"reference":"Between June 2024 and June 2025, the share of non-work-related ChatGPT messages increased significantly from 53% to 73%, indicating that non-work messages have grown faster and now represent more than 70% of all consumer ChatGPT messages.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"hw dose ChatGPT improove workr output?","reference_contexts":["Doing, and thatAskingmessages are consistently rated as having higher quality both by a classifier\nthat measures user satisfaction and from direct user feedback.\nHow does ChatGPT provide economic value, and for whom is its value the greatest? We argue that\nChatGPT likely improves worker output by providingdecision support, which is especially important in\nknowledge-intensive jobs where better decision-making increases productivity (Deming, 2021; Caplin et\nal., 2023). This explains whyAskingis relatively more common for educated users who are employed\nin highly-paid, professional occupations. Our findings are most consistent with Ide and Talamas\n(2025), who develop a model where AI agents can serve either asco-workersthat produce output or\nasco-pilotsthat give advice and improve the productivity of human problem-solving.\n2 What is ChatGPT?\nHere we give a simplified overview of LLMs and chatbots. For more precise details, refer to the papers\nand system cards that OpenAI has released with each model e.g., (OpenAI, 2023, 2024a, 2025b). A\nchatbot is a statistical model trained to generate a text response given some text input, so as to\nmaximize the \u201cquality\u201d of that response, where the quality is measured with a variety of metrics.\nIn a prototypical interaction, a user submits a plain-text message (\u201cprompt\u201d) and ChatGPT\nreturns the message (\u201cresponse\u201d) generated from an underlying LLM. A large set of additional features\nhave been added to ChatGPT\u2014including the possibility for the LLM to search the web or external\ndatabases, and generate images based on text\u2014but the exchange of text-based messages remains the\nmost typical interaction.\nSince its launch ChatGPT has used a variety of different underlying LLMs e.g., GPT-3.5, GPT-4,\nGPT-4o, o1, o3, and GPT-5. 12 In addition there are occasional updates to the model\u2019s weights and\nto the model\u2019s system prompt (text instructions sent to the model along with all the queries).\nAn LLM can be thought of as a function from a string of words to a probability distribution over\nthe set of all possible words (more precisely, \u201ctokens,\u201d which very roughly correspond to words13). The\nfunctions are implemented with deep neural nets, typically with a transformer architecture (Vaswani\net al., 2017), parameterized with billions of model \u201cweights\u201d. We will refer to all of ChatGPT\u2019s models\nas language models, though most can additionally process tokens representing images, audio, or other\nmedia.\nThe weights in an LLM-based chatbot are often trained in two stages, commonly called \u201cpre-\ntraining\u201d and \u201cpost-training\u201d. In the first stage (\u201cpre-training\u201d), the LLMs are trained to predict the\nnext word in a string, given the preceding words, over an enormous corpus of text. At that point the\nmodels are purely predictors of the likelihood of the next word given a prior context, and as such they\nhave a relatively narrow application. In the second stage (\u201cpost-training\u201d), the models are trained to\nproduce words that comprise \u201cgood\u201d responses to some prompt. This stage often consists of a variety\nof different strategies: fine-tuning on a dataset of queries and ideal responses, reinforcement learning\nagainst another model that is trained to grade the quality of a response (Ouyang et al., 2022), or\nreinforcement learning against a function that knows the true response to queries (OpenAI (2024b),\n12For a timeline of model launches, see Appendix C.\n13Tokenization is a way of cutting a string of text into discrete chunks, chosen to be statistically efficient. In many\ntokenization schemes, one token corresponds to roughly three-quarters of an English word.\n4"],"reference":"ChatGPT likely improves worker output by providing decision support, which is especially important in knowledge-intensive jobs where better decision-making increases productivity. This explains why asking is relatively more common for educated users who are employed in highly-paid, professional occupations.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"What trends have been observed in the share of ChatGPT queries related to paid work versus non-work from June 2024 to June 2025?","reference_contexts":["Figure 5:Daily messages sent per weekly active user, split by sign-up cohort. Sample only considers users of\nChatGPT consumer plans (Free, Plus, Pro). Reported values are moving averages of the past 90 days and are\nreported starting 90 days after the cohort is fully formed. Y-axis is an index normalized to the first reported\nvalue for the Q1 2023 cohort.\n5.1 What share of ChatGPT queries are related to paid work?\nWe label each user message in our dataset based on whether it appears to be related to work, using\nan LLM classifier. The critical part of the prompt is as follows: 21\nDoes the last user message of this conversation transcript seem likely to be related to doing\nsome work\/employment? Answer with one of the following:\n(1) likely part of work (e.g., \u201crewrite this HR complaint\u201d)\n(0) likely not part of work (e.g., \u201cdoes ice reduce pimples?\u201d)\nTable 1 shows that both types of queries grew rapidly between June 2024 and June 2025, however\nnon-work-related messages grew faster: 53% of messages were not related to work in June 2024, which\nclimbed to 73% by June 2025.\nFigure 6 plots the share of non-work messages decomposed by cumulative sign-up cohorts. Succes-\nsive cohorts have had a higher share of non-work messages, but also within each cohort their non-work\nuse has increased. Comparing the share among all users (black line) to the share among the earliest\ncohort of users (yellow line), we can see that they track very closely.\n21See Appendix A for the full prompt, see Appendix B for validation.\n12"],"reference":"Between June 2024 and June 2025, both work-related and non-work-related ChatGPT messages grew rapidly. However, non-work-related messages grew faster, increasing from 53% of messages in June 2024 to 73% by June 2025. Additionally, successive user sign-up cohorts have shown a higher share of non-work messages, and within each cohort, non-work use has also increased over time.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"What are the primary work-related activities reflected in ChatGPT usage according to the data?","reference_contexts":["Figure 13:Shares of Asking, Doing, and Expressing messages split by work vs. non-work. See A to review\nthe prompts used by the automated classifiers. The annotations on the right show the shares of work and\nnon-work for the full sample. Each bin reports a percentage of the total population. Shares are calculated\nfrom a sample of approximately 1.1 million sampled conversations from May 15, 2024 through June 26, 2025.\nObservations are reweighted to reflect total message volumes on a given day. Sampling details available in\nSection 3.\nO*NET taxonomy to map these classified IWAs to one of the Generalized Work Activities (GWA). We\ndo not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\nFigure 14 presents the share of messages that belong to each GWA, in descending order. Nearly\nhalf of all messages (45.2%) fall under just three GWAs related to information use and manipula-\ntion:Getting Information(19.3%),Interpreting the Meaning of Information for Others(13.1%), and\nDocumenting\/Recording Information(12.8%). The next most common work activities areProviding\nConsultation and Advice(9.2%),Thinking Creatively(9.1%),Making Decisions and Solving Problems\n(8.5%), andWorking with Computers(4.9%). These seven GWAs collectively account for 76.9% of\nall messages.\nFigure 15 presents the distribution of GWAs for the subsample of messages we classify as work-\nrelated. Among work-related messages, the most common GWAs areDocumenting\/Recording In-\nformation(18.4%),Making Decisions and Solving Problems(14.9%),Thinking Creatively(13.0%),\nWorking with Computers(10.8%),Interpreting the Meaning of Information for Others(10.1%),Get-\nting Information(9.3%), andProviding Consultation and Advice to Others(4.4%). These seven GWAs\ncollectively account for nearly 81% of work-related messages. Overall, the majority of ChatGPT usage\nat work appears to be focused on two broad functions: 1) obtaining, documenting, and interpreting\ninformation; and 2) making decisions, giving advice, solving problems, and thinking creatively.\n20"],"reference":"The primary work-related activities in ChatGPT usage focus on two broad functions: obtaining, documenting, and interpreting information; and making decisions, giving advice, solving problems, and thinking creatively. Specifically, among work-related messages, the most common Generalized Work Activities (GWAs) are Documenting\/Recording Information (18.4%), Making Decisions and Solving Problems (14.9%), Thinking Creatively (13.0%), Working with Computers (10.8%), Interpreting the Meaning of Information for Others (10.1%), Getting Information (9.3%), and Providing Consultation and Advice to Others (4.4%). These seven GWAs collectively account for nearly 81% of work-related messages.","synthesizer_name":"single_hop_specific_query_synthesizer"}
{"user_input":"What does Figure 14 illustrate about the classification of ChatGPT messages?","reference_contexts":["Figure 14:GWA Shares of 1.1M ChatGPT Messages. Messages are classified as pertaining to one of 332\nO*NET IWAs, orAmbiguoususing the prompt provided in the Appendix. IWAs were then aggregated to\nGWAs using the O*NET Work Activities taxonomy. Message sample from May 15, 2024 through June 26,\n2025. We do not show the shares for the following GWAs as there were fewer than 100 users sending messages\nfor each category and group them intoSuppressed.\n21"],"reference":"Figure 14 illustrates the GWA shares of 1.1 million ChatGPT messages, which are classified as pertaining to one of 332 O*NET IWAs or as Ambiguous using the prompt provided in the Appendix. These IWAs were then aggregated to GWAs using the O*NET Work Activities taxonomy. The message sample covers the period from May 15, 2024 through June 26, 2025. Shares for GWAs with fewer than 100 users sending messages are grouped into Suppressed.","synthesizer_name":"single_hop_specific_query_synthesizer"}
